{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark SQL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK9JOxYLVQQF"
      },
      "source": [
        "**Use of SQL in Spark: demonstrate data cleaning and merging**\n",
        "- Set up pyspark and sqlcontext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzXsB7MOWQxI",
        "outputId": "55e5bc0b-84e4-486b-eb6e-fae21ea11fe5"
      },
      "source": [
        "# install pyspark on local machinery\n",
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 67 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 60.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=28023bdfc3449b40c157e63ef4fbc043c0c909ae8563713f5b45da53bf8592fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1KEEKYxFX6EN",
        "outputId": "480996f4-46f1-42a0-b811-dd9165ee16c0"
      },
      "source": [
        "import pyspark\n",
        "pyspark.__version__\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.1.2'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCdpl7NzWuD0",
        "outputId": "678676e8-67c8-4032-b9ee-25d436395594"
      },
      "source": [
        "try:\n",
        "    print(sc)\n",
        "except NameError:\n",
        "    sc = pyspark.SparkContext('local[*]')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SparkContext master=local[*] appName=pyspark-shell>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrX4PaHmVle4",
        "outputId": "046a3ff4-d32e-40f4-9c91-50cc47142516"
      },
      "source": [
        "# Create a SQL context \n",
        "from pyspark.sql import SQLContext\n",
        "try:\n",
        "  print(sqlContext)\n",
        "except NameError:\n",
        "  sqlContext = SQLContext(sc)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pyspark.sql.context.SQLContext object at 0x7f024cde9390>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6_I2Uu2YQdJ"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "try:\n",
        "  print(spark)\n",
        "except NameError:\n",
        "  spark = SparkSession(sc)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWA6_0P4XUHG"
      },
      "source": [
        "**Use california housing data set to demonstrate the simple SQL queries such as SELECT columns, JOIN for merging datasets, and WHERE to subsetting data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt8d4T59XFqU",
        "outputId": "9fc5c8ff-d19f-4028-d6c0-905de0777821"
      },
      "source": [
        "# Load CSV file\n",
        "df1 = spark.read.format('csv').load(\"california_housing_train.csv\", header = True)\n",
        "df1.show(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population|households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000|472.000000|     1.493600|      66900.000000|\n",
            "|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000|463.000000|     1.820000|      80100.000000|\n",
            "|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000|117.000000|     1.650900|      85700.000000|\n",
            "|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000|226.000000|     3.191700|      73400.000000|\n",
            "|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000|262.000000|     1.925000|      65500.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujv9A1JCYtAM"
      },
      "source": [
        "# Register the dataframe df1 as temporary table to enable SQL commands\n",
        "df1.registerTempTable(\"housing\") "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXfMCJPkZCOr"
      },
      "source": [
        "**Run SQL queries to create a subset of dataset**\n",
        "\n",
        "---\n",
        "Select all columns and display rows that have `latitude` less than 34 and `longitude` greater than -115. Correctly make use of the `AND` operator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvRvDMz8ZHDS",
        "outputId": "814f3d83-a8c5-4b36-fe0a-6266673f272d"
      },
      "source": [
        "data = sqlContext.sql(\"\"\"\n",
        "                         SELECT *\n",
        "                         FROM housing\n",
        "                         WHERE (latitude < 34 AND longitude > -115) \"\"\")\n",
        "\n",
        "data.show(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population|households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000|117.000000|     1.650900|      85700.000000|\n",
            "|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000|226.000000|     3.191700|      73400.000000|\n",
            "|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000|262.000000|     1.925000|      65500.000000|\n",
            "|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000|239.000000|     3.343800|      74000.000000|\n",
            "|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000|633.000000|     2.676800|      82400.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeOFWQBOZsTN"
      },
      "source": [
        "**Create a subset of data with condition on the `population` greater than or equal to 10000, for only `households` column.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0bTmY-SZrfY",
        "outputId": "366e9c2c-e459-478d-9ad3-79bda564f22d"
      },
      "source": [
        "data2 = sqlContext.sql(\"\"\"\n",
        "                         SELECT households \n",
        "                         FROM housing\n",
        "                         WHERE population >= 10000 \"\"\")\n",
        "\n",
        "data2.show(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "| households|\n",
            "+-----------+\n",
            "|4339.000000|\n",
            "|4769.000000|\n",
            "|3832.000000|\n",
            "|5189.000000|\n",
            "|3258.000000|\n",
            "+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaM39VfHa_qK"
      },
      "source": [
        "\n",
        "Load the US population, area and Abbreviations datasets as a temporary table. Data source: http://github.com/jakevdp/data-USstates/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b0rB0LAbPHI",
        "outputId": "dca3a11f-8d23-47a0-dddd-f623105ef659"
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-population.csv\n",
        "!curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-areas.csv\n",
        "!curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-abbrevs.csv"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 57935  100 57935    0     0   342k      0 --:--:-- --:--:-- --:--:--  344k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   835  100   835    0     0   6139      0 --:--:-- --:--:-- --:--:--  6139\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   872  100   872    0     0   6140      0 --:--:-- --:--:-- --:--:--  6140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "523zazLtbWVw",
        "outputId": "fc7a131b-7f76-4de0-8fc8-329ec3069ed2"
      },
      "source": [
        "# register the tables for SQL commands\n",
        "# 1. create a dataframe from the csv files (make use of .read() and .load() as shown above)\n",
        "# 2. register the dataframe as a SQL table (again follow the steps given above.)\n",
        "\n",
        "# code here\n",
        "# Load dataset \n",
        "\n",
        "pop = spark.read.format('csv').load(\"state-population.csv\", header = True)\n",
        "area = spark.read.format('csv').load(\"state-areas.csv\", header = True)\n",
        "abbr = spark.read.format('csv').load(\"state-abbrevs.csv\", header = True)\n",
        "\n",
        "# Register\n",
        "\n",
        "pop.registerTempTable(\"population\") \n",
        "area.registerTempTable(\"area\") \n",
        "abbr.registerTempTable(\"abbr\") \n",
        "\n",
        "pop.show(5)\n",
        "area.show(5)\n",
        "abbr.show(5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-------+----+----------+\n",
            "|state/region|   ages|year|population|\n",
            "+------------+-------+----+----------+\n",
            "|          AL|under18|2012|   1117489|\n",
            "|          AL|  total|2012|   4817528|\n",
            "|          AL|under18|2010|   1130966|\n",
            "|          AL|  total|2010|   4785570|\n",
            "|          AL|under18|2011|   1125763|\n",
            "+------------+-------+----+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+-------------+\n",
            "|     state|area (sq. mi)|\n",
            "+----------+-------------+\n",
            "|   Alabama|        52423|\n",
            "|    Alaska|       656425|\n",
            "|   Arizona|       114006|\n",
            "|  Arkansas|        53182|\n",
            "|California|       163707|\n",
            "+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+------------+\n",
            "|     state|abbreviation|\n",
            "+----------+------------+\n",
            "|   Alabama|          AL|\n",
            "|    Alaska|          AK|\n",
            "|   Arizona|          AZ|\n",
            "|  Arkansas|          AR|\n",
            "|California|          CA|\n",
            "+----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpsfNiQFbjSu"
      },
      "source": [
        "# JOINS\n",
        "join to merge the state-abbrevs with state-population on the state/region column in state-population table and on the abbreviation column in state-abbrevs table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5GM0hTTboZ2",
        "outputId": "dcc1f8f6-c973-4ecc-b9ce-0b0dd64853ca"
      },
      "source": [
        "prob5 = sqlContext.sql(\"\"\"\n",
        "                         SELECT *                             \n",
        "                         FROM abbr\n",
        "                         FULL OUTER JOIN population\n",
        "                         ON abbr.abbreviation = population.`state/region`\n",
        "                          \"\"\")\n",
        "\n",
        "prob5.show(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------+------------+-------+----+----------+\n",
            "|  state|abbreviation|state/region|   ages|year|population|\n",
            "+-------+------------+------------+-------+----+----------+\n",
            "|Arizona|          AZ|          AZ|under18|2012|   1617149|\n",
            "|Arizona|          AZ|          AZ|  total|2012|   6551149|\n",
            "|Arizona|          AZ|          AZ|under18|2011|   1616353|\n",
            "|Arizona|          AZ|          AZ|  total|2011|   6468796|\n",
            "|Arizona|          AZ|          AZ|under18|2010|   1628563|\n",
            "+-------+------------+------------+-------+----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}